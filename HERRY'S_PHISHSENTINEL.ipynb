{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Omotola203/-Bettercap-HQ-Pen-Testing/blob/main/HERRY'S_PHISHSENTINEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMrLwiJVzs3q",
        "outputId": "4202dbad-ddbb-4b3b-ea74-031bb26f4b43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to Herry's PhishSentinel, your vigilant guardian against phishing threats. Protecting your digital world, one click at a time.\n",
            "Enter the URL to check (or type 'exit' to quit): https://deepai.org\n",
            "https://deepai.org is a phishing attack!\n",
            "Enter the URL to check (or type 'exit' to quit): https://www.kaggle.com\n",
            "https://www.kaggle.com is a phishing attack!\n",
            "Enter the URL to check (or type 'exit' to quit): https://www.razer.com\n",
            "https://www.razer.com is not a phishing attack.\n",
            "Enter the URL to check (or type 'exit' to quit): exit\n",
            "Exiting the phishing detector. Looking forward to seeing you again. Stay safe and goodbye!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import os\n",
        "from urllib.parse import urlparse\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from requests import get, RequestException\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the list of phishing indicators\n",
        "phishing_indicators = [\n",
        "    \"login.php\", \"member.php\", \"register.php\", \"forgot.php\", \"change.php\",\n",
        "    \"account.php\", \"password.php\", \"profile.php\", \"update.php\",\n",
        "    \"password-recovery.php\", \"recover.php\", \"reset.php\", \"retrieve.php\"\n",
        "]\n",
        "\n",
        "# Load known safe domains from the 'top-1m.csv' file\n",
        "def load_safe_domains():\n",
        "    try:\n",
        "        df = pd.read_csv('top-1m.csv', header=None, encoding='ISO-8859-1')\n",
        "        safe_domains = df[1].tolist()  # The domains are in the second column\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: 'top-1m.csv' file not found.\")\n",
        "        safe_domains = [\n",
        "   \"google.com\", \"wikipedia.org\", \"amazon.com\", \"github.com\", \"microsoft.com\", \"youtube.com\", \"bbc.com\", \"nytimes.com\",\n",
        "\"coursera.org\", \"stackoverflow.com\", \"deepai.org\", \"spotify.com\", \"slack.com\", \"zoom.us\", \"cloudflare.com\", \"godaddy.com\",\n",
        "\"bbc.com\", \"cnn.com\", \"nytimes.com\", \"theguardian.com\", \"forbes.com\", \"bloomberg.com\", \"wsj.com\", \"nationalgeographic.com\",\n",
        "\"weather.com\", \"airbnb.com\", \"uber.com\", \"lyft.com\", \"booking.com\", \"expedia.com\", \"tripadvisor.com\", \"nike.com\",\n",
        "\"adidas.com\", \"zara.com\", \"hm.com\", \"sephora.com\", \"macys.com\", \"walmart.com\", \"target.com\", \"costco.com\",\n",
        "\"bestbuy.com\", \"homedepot.com\", \"lowes.com\", \"ikea.com\", \"wholefoodsmarket.com\", \"walgreens.com\", \"cvs.com\", \"samsung.com\",\n",
        "\"sony.com\", \"lg.com\", \"dell.com\", \"hp.com\", \"asus.com\", \"lenovo.com\", \"acer.com\", \"msi.com\",\n",
        "\"razer.com\", \"logitech.com\", \"autodesk.com\", \"sketchup.com\", \"blender.org\", \"zendesk.com\", \"freshdesk.com\", \"trello.com\",\n",
        "\"asana.com\", \"jira.com\", \"bitbucket.org\", \"toggl.com\", \"hubspot.com\", \"mailchimp.com\", \"constantcontact.com\", \"activecampaign.com\",\n",
        "\"getresponse.com\", \"aweber.com\", \"sendinblue.com\", \"zoho.com\", \"monday.com\", \"smartsheet.com\", \"clickup.com\", \"wrike.com\",\n",
        "\"basecamp.com\", \"notion.so\", \"evernote.com\", \"onenote.com\", \"todoist.com\", \"ticktick.com\", \"habitica.com\", \"toggl.com\",\n",
        "\"rescuetime.com\", \"myhours.com\", \"clockify.me\", \"timecamp.com\", \"harvestapp.com\", \"freckle.com\", \"hourstack.com\", \"timedoctor.com\",\n",
        "\"hubstaff.com\", \"paymoapp.com\", \"tickspot.com\", \"payscale.com\", \"glassdoor.com\", \"indeed.com\", \"monster.com\", \"ziprecruiter.com\",\n",
        "\"angel.co\", \"linkedin.com/jobs\", \"simplyhired.com\", \"careerbuilder.com\", \"dice.com\", \"hired.com\", \"thebalancecareers.com\", \"roberthalf.com\",\n",
        "\"randstadusa.com\", \"adeccousa.com\", \"kellyservices.us\", \"manpower.com\", \"expresspros.com\", \"careerarc.com\", \"snagajob.com\", \"wayup.com\",\n",
        "\"collegegrad.com\", \"internships.com\", \"govtjobs.com\", \"federaljobs.net\", \"usajobs.gov\", \"state.gov\", \"cityjobs.com\", \"countyjobs.com\",\n",
        "\"districtjobs.com\", \"publicservicecareers.org\", \"teachercatapult.com\", \"educationamerica.net\", \"higheredjobs.com\", \"chroniclevitae.com\", \"k12jobspot.com\", \"academiccareers.com\",\n",
        "\"employmentcrossing.com\", \"nationjob.com\", \"jobbankusa.com\", \"jobhero.com\", \"jobfox.com\", \"job-hunt.org\", \"localwise.com\", \"meetup.com\",\n",
        "\"eventbrite.com\", \"tickettailor.com\", \"peerspace.com\", \"breather.com\", \"wework.com\", \"regus.com\", \"knotel.com\", \"convene.com\",\n",
        "\"industriousoffice.com\", \"davincivirtual.com\", \"opusoffices.com\", \"cloudvo.com\", \"liquidspace.com\", \"croissant.io\", \"workfrom.co\", \"workbar.com\",\n",
        "\"serendipitylabs.com\", \"workthere.com\", \"servcorp.com\", \"spacesworks.com\", \"coworker.com\", \"coworkingresources.org\", \"workspot.com\", \"maple.com\",\n",
        "\"robinpowered.com\", \"eden.io\", \"officeotp.com\", \"birdoffice.com\", \"optixapp.com\", \"deskpass.com\", \"myhq.in\", \"hubblehq.com\",\n",
        "\"baremetrics.com\", \"chartmogul.com\", \"profitwell.com\", \"clientbooks.com\", \"pulseapp.com\", \"bill.com\", \"xero.com\", \"quickbooks.intuit.com\",\n",
        "\"freshbooks.com\", \"waveapps.com\", \"sage.com\", \"kashoo.com\", \"outright.com\", \"freeagent.com\", \"zipbooks.com\", \"zoho.com/books\",\n",
        "\"lessaccounting.com\", \"invoiceninja.com\", \"and.co\", \"bokio.co.uk\", \"invoicehome.com\", \"invoiceberry.com\", \"invoice2go.com\", \"simpleinvoices.com\",\n",
        "\"sliqtools.co.uk\", \"free-invoice.co.uk\", \"streetinvoice.com\", \"invoicely.com\", \"cashboardapp.com\", \"getharvest.com\", \"timecamp.com\", \"toggl.com\",\n",
        "\"myhours.com\", \"clockify.me\", \"hubstaff.com\", \"worksnaps.net\", \"workpuls.com\", \"desktime.com\", \"paymoapp.com\", \"timewatch.com\",\n",
        "\"tsheets.com\", \"timedoctor.com\", \"rescuetime.com\", \"timeular.com\", \"teamwork.com\", \"asana.com\", \"monday.com\", \"wrike.com\",\n",
        "\"clickup.com\", \"notion.so\", \"trello.com\", \"basecamp.com\", \"smartsheet.com\", \"airtable.com\", \"qube-os.com\", \"flow.com\",\n",
        "\"getflow.com\", \"teamgantt.com\", \"goodday.work\", \"proofhub.com\", \"taskworld.com\", \"azendoo.com\", \"projectplace.com\", \"mavenlink.com\",\n",
        "\"nutcache.com\", \"redbooth.com\", \"scoro.com\", \"kanbanflow.com\", \"kanbanchi.com\", \"taskque.com\", \"workzone.com\", \"clarizen.com\",\n",
        "\"liquidplanner.com\", \"workfront.com\", \"targetprocess.com\", \"daptiv.com\", \"projectinsight.net\", \"functionfox.com\", \"projectmanager.com\", \"project-open.com\",\n",
        "\"ganttpro.com\", \"easyprojects.net\", \"sciforma.com\", \"bigtime.net\", \"teamworkpm.net\", \"celoxis.com\", \"appfluence.com\", \"prioritymatrix.com\",\n",
        "\"viewpath.com\", \"rindle.com\", \"hey.space\", \"volerro.com\", \"activecollab.com\", \"taskade.com\", \"glasscubes.com\", \"plan.io\",\n",
        "\"clockodo.com\", \"intervals.com\", \"breeze.pm\", \"planzone.com\", \"bubbl.us\", \"mindmeister.com\", \"coggle.it\", \"xmind.net\",\n",
        "\"mindmup.com\", \"thebrain.com\", \"stormboard.com\", \"popplet.com\", \"mindomo.com\", \"simplemind.eu\", \"mindlyapp.com\", \"freemind.sourceforge.net\",\n",
        "\"mindmapper.com\", \"mapul.com\", \"mindgenius.com\", \"inspiration.com\", \"conceptdraw.com\", \"creately.com\", \"smartdraw.com\", \"lucidchart.com\",\n",
        "\"gliffy.com\", \"draw.io\", \"diagrams.net\", \"cacoo.com\", \"whimsical.com\", \"canva.com\", \"visme.co\", \"piktochart.com\",\n",
        "\"venngage.com\", \"infogram.com\", \"easel.ly\", \"visualize.me\", \"adobe.com/products/illustrator\", \"coreldraw.com\", \"sketch.com\", \"affinity.serif.com\",\n",
        "\"inkscape.org\", \"gravit.io\", \"vectornator.io\", \"vectr.com\", \"svg-edit.googlecode.com\", \"autodesk.com/products/autocad\", \"sketchup.com\", \"tinkercad.com\",\n",
        "\"3ds.com\", \"blender.org\", \"freecadweb.org\", \"opencascade.com\", \"onshape.com\", \"fusion360.autodesk.com\", \"solidworks.com\", \"ironcad.com\",\n",
        "\"rhino3d.com\", \"solidthinking.com\", \"siemens.com/software/solid-edge\", \"vectorworks.net\", \"bentley.com\", \"3d-coat.com\", \"mari.org\", \"keyshot.com\",\n",
        "\"lumion.com\", \"unrealengine.com\", \"unity3d.com\", \"cryengine.com\", \"godotengine.org\", \"houdini.com\", \"marmoset.co\", \"substance3d.com\",\n",
        "\"adobe.com/products/dimension\", \"zbrushcentral.com\", \"autodesk.com/products/maya\", \"pixologic.com\", \"maxon.net\", \"planetside.co.uk\", \"terragen.com\", \"world-machine.com\",\n",
        "\"gaea.mydaxdev.com\", \"vue.bentley.com\", \"quixel.com\", \"megascans.se\", \"bridge.se\", \"mixer.se\", \"allegorithmic.com\", \"substance3d.com\",\n",
        "\"x-normal.net\", \"knaldtech.com\", \"crazybump.com\", \"microsoft.com/pt-br/windows/photos\", \"adobe.com/products/photoshop\", \"gimp.org\", \"krita.org\", \"paint\n",
        "\n",
        "        ]\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error: {e}. Could not decode 'top-1m.csv'.\")\n",
        "        safe_domains = []\n",
        "    return safe_domains\n",
        "\n",
        "# List of known safe domains\n",
        "safe_domains = load_safe_domains()\n",
        "\n",
        "def extract_features(url):\n",
        "    features = {}\n",
        "    parsed_url = urlparse(url)\n",
        "    domain = parsed_url.netloc\n",
        "\n",
        "    # Feature: Domain length\n",
        "    features['domain_length'] = len(domain)\n",
        "\n",
        "    # Feature: URL length\n",
        "    features['url_length'] = len(url)\n",
        "\n",
        "    # Feature: Count of dots in domain\n",
        "    features['dot_count'] = domain.count('.')\n",
        "\n",
        "    # Feature: Count of phishing indicators in path\n",
        "    features['phishing_indicators_count'] = sum(indicator in parsed_url.path for indicator in phishing_indicators)\n",
        "\n",
        "    return features\n",
        "\n",
        "def train_model(dataset_path):\n",
        "    # Load the cleaned dataset\n",
        "    try:\n",
        "        df = pd.read_csv(dataset_path, low_memory=False, encoding='ISO-8859-1')  # or try 'cp1252'\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Dataset file not found at '{dataset_path}'. Please check the file path and try again.\")\n",
        "        return\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"Error: Dataset could not be parsed. Please check the file format and try again. ParserError: {e}\")\n",
        "        return\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error: {e}. Could not decode the dataset file.\")\n",
        "        return\n",
        "\n",
        "    # Ensure the dataset contains 'url' and 'label' columns\n",
        "    if 'url' not in df.columns or 'label' not in df.columns:\n",
        "        print(\"Error: The dataset must contain 'url' and 'label' columns.\")\n",
        "        return\n",
        "\n",
        "    # Extract features for each URL\n",
        "    feature_df = pd.DataFrame(df['url'].apply(extract_features).tolist())\n",
        "\n",
        "    # Create feature matrix and label vector\n",
        "    X = pd.concat([df, feature_df], axis=1).drop(columns=['url', 'label'])\n",
        "    y = df['label']\n",
        "\n",
        "    # Split the data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train a random forest classifier\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Save the trained model\n",
        "    joblib.dump(model, 'phishing_classifier.pkl')\n",
        "\n",
        "def detect_phishing(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    domain = parsed_url.netloc\n",
        "\n",
        "    # Check if the domain is in the list of known safe domains\n",
        "    if any(domain.endswith(safe_domain) for safe_domain in safe_domains):\n",
        "        return False\n",
        "\n",
        "    # Check if the URL contains any phishing indicators in its path\n",
        "    if any(indicator in parsed_url.path for indicator in phishing_indicators):\n",
        "        return True\n",
        "\n",
        "    try:\n",
        "        # Send a request to the URL and get the HTML response\n",
        "        response = get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "    except RequestException:\n",
        "        return True  # Treat any request issues as suspicious\n",
        "\n",
        "    soup = bs4.BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Check if the page has suspicious HTML content\n",
        "    content = soup.get_text()\n",
        "    if re.search(r\"password|username|email|account|login|logout|register|forgot\", content, re.IGNORECASE):\n",
        "        return True\n",
        "\n",
        "    # Check if the URL has a suspicious file extension\n",
        "    file_extension = os.path.splitext(parsed_url.path)[1]\n",
        "    if file_extension in [\".exe\", \".zip\", \".rar\", \".tar\", \".gz\"]:\n",
        "        return True\n",
        "\n",
        "    # Extract features for the URL\n",
        "    features = extract_features(url)\n",
        "    features_df = pd.DataFrame([features])\n",
        "\n",
        "    # Load the trained model\n",
        "    model = joblib.load('phishing_classifier.pkl')\n",
        "\n",
        "    # Predict using the trained model\n",
        "    is_phishing = model.predict(features_df)[0]\n",
        "\n",
        "    return bool(is_phishing)\n",
        "\n",
        "def main():\n",
        "    # Path to your cleaned dataset file\n",
        "    cleaned_dataset_path = 'cleaned_dataset_phishing.csv'\n",
        "\n",
        "    # Train the model with the specified dataset\n",
        "    train_model(dataset_path=cleaned_dataset_path)\n",
        "\n",
        "    print(\"Welcome to Herry's PhishSentinel, your vigilant guardian against phishing threats. Protecting your digital world, one click at a time.\")\n",
        "    while True:\n",
        "        # Get the URL from the user\n",
        "        url = input(\"Enter the URL to check (or type 'exit' to quit): \").strip()\n",
        "\n",
        "        # Check if the user wants to exit\n",
        "        if url.lower() == 'exit':\n",
        "            print(\"Exiting the phishing detector. Looking forward to seeing you again. Stay safe and goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Detect phishing attack\n",
        "        is_phishing = detect_phishing(url)\n",
        "\n",
        "        # Print the result\n",
        "        if is_phishing:\n",
        "            print(f\"{url} is a phishing URL!\")\n",
        "        else:\n",
        "            print(f\"{url} is not a phishing URL!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2wqJ4CiHkE54AgoYytxCB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}